{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis\n",
    "[Great PCA explanation](http://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from codefiles.datagen import random_xy, x_plus_noise, data_3d\n",
    "from codefiles.dataplot import plot_principal_components, plot_3d, plot_2d\n",
    "# %matplotlib inline\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D Correlated Data\n",
    "Now for the most interesting part! Let's use the PCA to actually reduce our data dimensionality (from 3D to 2D). First, generate 3D data: kind of thin surface with some noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_3D_corr = data_3d(num_points=1000, randomness=0.01, theta_x=30, theta_z=60)\n",
    "plot_3d(data_3D_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_3d = PCA()\n",
    "pca_3d.fit(data_3D_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variance corresponding to each principal component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('P.C. #0 explained variance: %0.7f' % pca_3d.explained_variance_ratio_[0])\n",
    "print('P.C. #1 explained variance: %0.7f' % pca_3d.explained_variance_ratio_[1])\n",
    "print('P.C. #2 explained variance: %0.7f' % pca_3d.explained_variance_ratio_[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the **order of magnitude** of difference among the 3. At least one of them is not very informative... Let's **transform** our dataset with the PCA and see how it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_flat = pca_3d.transform(data_3D_corr)\n",
    "data_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep the 3D dimensionality with the three P.C. (P.C. 0, P.C. 1 and P.C. 2) but we see now the third column (P.C. 2) with magnitude values much lower than the other ones (P.C. 0 and P.C. 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_principal_components(data_flat, x1=0, x2=1)\n",
    "plt.axis('equal')\n",
    "plt.title('The most informative (more spread/more variance) view of the data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above plot, P.C. 0 more informative than P.C. 1. And next, the comparison between P.C. 1 and P.C. 2 (the one we suspect it is not that informative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_principal_components(data_flat, x1=1, x2=2)\n",
    "plt.title('A less informative (less spread/less variance) view of the data')\n",
    "plt.xlim([-25,25])\n",
    "plt.ylim([-25,25])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, if we were in a process of dimensionality reduction then we would be able to extract two components without significant loss of information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus - Just out of curiosity...\n",
    "Up there we generated a 3D dataset with the following process:  \n",
    "1) Correlated data on `x`, `y`, and `z` axis  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generated not rotated dataset\n",
    "data_3D_corr_0 = data_3d(num_points=1000, randomness=0.01, theta_x=0, theta_z=0)\n",
    "\n",
    "# Plotting\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "xs = data_3D_corr_0['x'].values\n",
    "ys = data_3D_corr_0['y'].values\n",
    "zs = data_3D_corr_0['z'].values\n",
    "ax.scatter(xs, ys, zs)\n",
    "ax.set_xlim3d(-20, 20)\n",
    "ax.set_ylim3d(-20, 20)\n",
    "ax.set_zlim3d(-20, 20)\n",
    "plt.title('Data not rotated')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Then we rotated the data around the `z` axis and the `x` axis, of `60` and `30` degrees respectively (by this order!) and we ended up with the first plot in this notebook (check it above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from codefiles.datagen import _rot_mat_z, _rot_mat_x\n",
    "\n",
    "# Rotation angles in degrees\n",
    "theta_x = 30\n",
    "theta_z = 60\n",
    "\n",
    "# The rotation matrix is given by: Rot_x * Rot_z\n",
    "rotation_matrix = np.dot(_rot_mat_x(theta=np.radians(theta_x)), _rot_mat_z(theta=np.radians(theta_z)))\n",
    "rotation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, just check the *transformation* the PCA did above to our dataset (we need to transpose it since it is the inverse transformation): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_3d.components_.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks familiar? :) The PCA just found what we've done! If we did not rotate our dataset, the rotation matrix would have been a 3x3 identity matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
